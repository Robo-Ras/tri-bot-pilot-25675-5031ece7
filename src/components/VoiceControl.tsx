import { useState, useEffect, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { Card } from '@/components/ui/card';
import { Mic, MicOff } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';

interface VoiceControlProps {
  onSendCommand: (m1: number, m2: number, m3: number) => void;
  onToggleAutonomous: (enabled: boolean) => void;
  isConnected: boolean;
}

const VoiceControl = ({ onSendCommand, onToggleAutonomous, isConnected }: VoiceControlProps) => {
  const [isListening, setIsListening] = useState(false);
  const [lastCommand, setLastCommand] = useState<string>('');
  const [transcript, setTranscript] = useState<string>('');
  const recognitionRef = useRef<any>(null);
  const { toast } = useToast();

  useEffect(() => {
    console.log('üéôÔ∏è Inicializando Web Speech API...');
    
    // Verificar se o navegador suporta Web Speech API
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      console.error('‚ùå Navegador n√£o suporta Web Speech API');
      toast({
        title: "Navegador n√£o suportado",
        description: "Seu navegador n√£o suporta reconhecimento de voz. Use Chrome ou Edge.",
        variant: "destructive",
      });
      return;
    }

    // @ts-ignore
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'pt-BR';
    recognition.maxAlternatives = 1;

    console.log('‚úÖ Web Speech API configurada:', {
      continuous: recognition.continuous,
      interimResults: recognition.interimResults,
      lang: recognition.lang
    });

    recognition.onstart = () => {
      console.log('üé§ Reconhecimento de voz INICIADO');
    };

    recognition.onresult = (event: any) => {
      const current = event.resultIndex;
      const transcript = event.results[current][0].transcript.toLowerCase().trim();
      const confidence = event.results[current][0].confidence;
      
      console.log('üìù Transcri√ß√£o:', transcript, '| Confian√ßa:', confidence);
      setTranscript(transcript);

      // S√≥ processar comandos quando for resultado final
      if (event.results[current].isFinal) {
        console.log('‚úÖ Resultado final:', transcript);
        processCommand(transcript);
      }
    };

    recognition.onerror = (event: any) => {
      console.error('‚ùå Erro no reconhecimento de voz:', event.error);
      if (event.error === 'no-speech') {
        console.log('‚ÑπÔ∏è Nenhuma fala detectada (normal)');
        return;
      }
      if (event.error === 'not-allowed') {
        toast({
          title: "Permiss√£o Negada",
          description: "Permita o acesso ao microfone nas configura√ß√µes do navegador",
          variant: "destructive",
        });
        setIsListening(false);
        return;
      }
      toast({
        title: "Erro no reconhecimento",
        description: `Erro: ${event.error}`,
        variant: "destructive",
      });
    };

    recognition.onend = () => {
      console.log('‚èπÔ∏è Reconhecimento de voz FINALIZADO');
      // Reiniciar automaticamente se ainda estiver no modo listening
      if (isListening) {
        console.log('üîÑ Reiniciando reconhecimento...');
        try {
          recognition.start();
        } catch (error) {
          console.error('‚ùå Erro ao reiniciar:', error);
          setIsListening(false);
        }
      }
    };

    recognitionRef.current = recognition;

    return () => {
      console.log('üßπ Limpando reconhecimento de voz');
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [isListening]);

  const processCommand = (command: string) => {
    console.log('Processando comando:', command);
    
    const SPEED = 60;

    // Comandos de movimento
    if (command.includes('frente') || command.includes('para frente')) {
      onSendCommand(-SPEED, 0, SPEED);
      setLastCommand('Frente');
      toast({ title: "Comando de Voz", description: "Movendo para frente" });
    } 
    else if (command.includes('tr√°s') || command.includes('para tr√°s') || command.includes('tras')) {
      onSendCommand(SPEED, 0, -SPEED);
      setLastCommand('Tr√°s');
      toast({ title: "Comando de Voz", description: "Movendo para tr√°s" });
    } 
    else if (command.includes('direita') || command.includes('para direita')) {
      onSendCommand(0, SPEED, -SPEED);
      setLastCommand('Direita');
      toast({ title: "Comando de Voz", description: "Movendo para direita" });
    } 
    else if (command.includes('esquerda') || command.includes('para esquerda')) {
      onSendCommand(0, -SPEED, SPEED);
      setLastCommand('Esquerda');
      toast({ title: "Comando de Voz", description: "Movendo para esquerda" });
    } 
    else if (command.includes('parar') || command.includes('pare')) {
      onSendCommand(0, 0, 0);
      setLastCommand('Parar');
      toast({ title: "Comando de Voz", description: "Rob√¥ parado" });
    }
    // Comando de modo aut√¥nomo
    else if (command.includes('aut√¥nomo') || command.includes('autonomo') || 
             command.includes('modo aut√¥nomo') || command.includes('modo autonomo')) {
      onToggleAutonomous(true);
      setLastCommand('Modo Aut√¥nomo Ativado');
      toast({ title: "Comando de Voz", description: "Modo aut√¥nomo ativado" });
    }
    else if (command.includes('manual') || command.includes('modo manual')) {
      onToggleAutonomous(false);
      setLastCommand('Modo Manual Ativado');
      toast({ title: "Comando de Voz", description: "Modo manual ativado" });
    }
  };

  const toggleListening = async () => {
    console.log('üé§ Toggle listening. Estado atual:', isListening, '| Conectado:', isConnected);
    
    if (!isConnected) {
      toast({
        title: "Rob√¥ Desconectado",
        description: "Conecte-se ao rob√¥ antes de usar comandos de voz",
        variant: "destructive",
      });
      return;
    }

    if (isListening) {
      console.log('üõë Desativando reconhecimento...');
      recognitionRef.current?.stop();
      setIsListening(false);
      setTranscript('');
      toast({
        title: "Reconhecimento Desativado",
        description: "Comandos de voz desativados",
      });
    } else {
      try {
        console.log('‚ñ∂Ô∏è Solicitando permiss√£o do microfone...');
        
        // Solicitar permiss√£o do microfone primeiro
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('‚úÖ Permiss√£o concedida');
        stream.getTracks().forEach(track => track.stop()); // Liberar stream
        
        console.log('‚ñ∂Ô∏è Iniciando reconhecimento...');
        recognitionRef.current?.start();
        setIsListening(true);
        toast({
          title: "Reconhecimento Ativado",
          description: "üé§ Comandos: frente, tr√°s, direita, esquerda, parar, modo aut√¥nomo",
        });
      } catch (error) {
        console.error('‚ùå Erro ao acessar microfone:', error);
        toast({
          title: "Erro de Permiss√£o",
          description: "Permita o acesso ao microfone nas configura√ß√µes do navegador",
          variant: "destructive",
        });
      }
    }
  };

  return (
    <Card className="p-6">
      <div className="space-y-4">
        <div className="flex items-center justify-between">
          <div>
            <h3 className="text-lg font-semibold">Controle por Voz</h3>
            <p className="text-sm text-muted-foreground">
              Comandos: frente, tr√°s, direita, esquerda, parar, modo aut√¥nomo
            </p>
          </div>
          <Button
            onClick={toggleListening}
            size="lg"
            variant={isListening ? 'default' : 'outline'}
            className="gap-2"
            disabled={!isConnected}
          >
            {isListening ? (
              <>
                <Mic className="h-5 w-5" />
                Escutando...
              </>
            ) : (
              <>
                <MicOff className="h-5 w-5" />
                Ativar Voz
              </>
            )}
          </Button>
        </div>

        {isListening && (
          <div className="space-y-2">
            <div className="p-3 bg-muted rounded-md">
              <p className="text-sm text-muted-foreground">Ouvindo:</p>
              <p className="text-base font-medium">{transcript || 'Aguardando comando...'}</p>
            </div>
            {lastCommand && (
              <div className="p-3 bg-primary/10 rounded-md">
                <p className="text-sm text-muted-foreground">√öltimo comando executado:</p>
                <p className="text-base font-semibold text-primary">{lastCommand}</p>
              </div>
            )}
          </div>
        )}

        {!isConnected && (
          <div className="p-3 bg-destructive/10 rounded-md">
            <p className="text-sm text-destructive">
              Conecte-se ao servidor Python para usar comandos de voz
            </p>
          </div>
        )}
      </div>
    </Card>
  );
};

export default VoiceControl;
